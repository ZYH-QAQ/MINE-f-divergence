{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliced Mutual Information Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Estimator\n",
    "According to the paper, it is necessary to define an MI estimator for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Mutual Information Neural Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MINE(nn.Module):\n",
    "    def __init__(self, x_size, y_size, proj_size=32):\n",
    "        super(MINE, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_size, proj_size)\n",
    "        self.fc2 = nn.Linear(y_size, proj_size)\n",
    "        self.fc3 = nn.Linear(proj_size, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        h = self.fc1(x) + self.fc2(y)\n",
    "        h = F.relu(h)\n",
    "        return self.fc4(F.relu(self.fc3(h)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mine(x, y, num_epoch=500):\n",
    "    model = MINE(x.shape[1], y.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    S_sample = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True)\n",
    "    w_sample = Variable(torch.from_numpy(y).type(torch.FloatTensor), requires_grad=True)\n",
    "    w_shuffe_sample = Variable(torch.from_numpy(np.random.permutation(y)).type(torch.FloatTensor), requires_grad=True)\n",
    "    \n",
    "    mi = []\n",
    "    for _ in range(num_epoch):\n",
    "        pred_xy = model(S_sample, w_sample)\n",
    "        pred_x_y = model(S_sample, w_shuffe_sample)\n",
    "    \n",
    "        loss1 = -torch.mean(pred_xy)\n",
    "        loss2 = torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        mi.append((-loss).data.numpy())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return mi[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.RBIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estmate_smi(m: int, X, Y, pair_num: int, mi_calculator):\n",
    "    def hyperspherical_sample(num: int, dim: int) -> np.ndarray:\n",
    "        angles = np.random.uniform(0, 2*np.pi, size=(num, dim-1))\n",
    "        coord = np.zeros((num, dim))\n",
    "        coord[:, :-1] = np.cos(angles)\n",
    "        coord[:, -1] = np.sin(angles[:, -1])\n",
    "        return coord\n",
    "    \n",
    "    num_x = X.shape[0]\n",
    "    num_y = Y.shape[0]\n",
    "    dim_x = X.shape[1]\n",
    "    dim_y = Y.shape[1]\n",
    "    S = []\n",
    "    for _ in tqdm(range(m)):\n",
    "        theta = hyperspherical_sample(num=num_x, dim=dim_x)\n",
    "        phi = hyperspherical_sample(num=num_y, dim=dim_y)\n",
    "        \n",
    "        theta = np.linalg.norm(theta)\n",
    "        phi = np.linalg.norm(phi)\n",
    "        \n",
    "        X_input = np.dot(theta.T, X)\n",
    "        Y_input = np.dot(phi.T, Y)\n",
    "        \n",
    "        _S = mi_calculator(X_input, Y_input)\n",
    "        S.append(_S)\n",
    "    \n",
    "    S = np.array(S)\n",
    "    return np.sum(S) / m\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(0, 0.3, (1000, 10))\n",
    "Y = np.random.normal(0,3, (1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 8/500 [00:17<17:52,  2.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\llt02\\Desktop\\Codes\\sliced_mi\\sliced_mutual_information.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mi_calculator \u001b[39m=\u001b[39m train_mine\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m si \u001b[39m=\u001b[39m estmate_smi(\u001b[39m500\u001b[39;49m, X, Y, \u001b[39m1000\u001b[39;49m, mi_calculator\u001b[39m=\u001b[39;49mmi_calculator)\n",
      "\u001b[1;32mc:\\Users\\llt02\\Desktop\\Codes\\sliced_mi\\sliced_mutual_information.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     X_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(theta\u001b[39m.\u001b[39mT, X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     Y_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(phi\u001b[39m.\u001b[39mT, Y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     _S \u001b[39m=\u001b[39m mi_calculator(X_input, Y_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     S\u001b[39m.\u001b[39mappend(_S)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m S \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(S)\n",
      "\u001b[1;32mc:\\Users\\llt02\\Desktop\\Codes\\sliced_mi\\sliced_mutual_information.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     mi\u001b[39m.\u001b[39mappend((\u001b[39m-\u001b[39mloss)\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/llt02/Desktop/Codes/sliced_mi/sliced_mutual_information.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mi[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mi_calculator = train_mine\n",
    "si = estmate_smi(500, X, Y, 1000, mi_calculator=mi_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(si)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
